import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, roc_auc_score, roc_curve, confusion_matrix,
    precision_recall_curve
)

sns.set(style="whitegrid")
plt.rcParams["font.family"] = "sans-serif"
plt.rcParams["font.sans-serif"] = ["Arial"]

# 生成虚拟数据
X, y = make_classification(
    n_samples=1000, n_features=10, n_informative=5,
    n_redundant=2, n_classes=2, random_state=42
)
X = pd.DataFrame(X, columns=[f"Feature {i}" for i in range(1, 11)])
y = pd.Series(y, name="Target")

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 模型训练
lr_model = LogisticRegression(max_iter=1000)
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")

lr_model.fit(X_train, y_train)
xgb_model.fit(X_train, y_train)

# 模型预测概率
y_pred_prob_lr = lr_model.predict_proba(X_test)[:, 1]
y_pred_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]

# ROC曲线
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_prob_lr)
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_prob_xgb)

# PR曲线
precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_pred_prob_lr)
precision_xgb, recall_xgb, _ = precision_recall_curve(y_test, y_pred_prob_xgb)

# 混淆矩阵
cm_lr = confusion_matrix(y_test, lr_model.predict(X_test))
cm_xgb = confusion_matrix(y_test, xgb_model.predict(X_test))

# AUC
auc_lr = roc_auc_score(y_test, y_pred_prob_lr)
auc_xgb = roc_auc_score(y_test, y_pred_prob_xgb)

# 开始画图（四合一图）
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# ROC 曲线
axes[0, 0].plot(fpr_lr, tpr_lr, label=f"Logistic Regression (AUC = {auc_lr:.2f})", color="dodgerblue", linewidth=2)
axes[0, 0].plot(fpr_xgb, tpr_xgb, label=f"XGBoost (AUC = {auc_xgb:.2f})", color="orange", linewidth=2)
axes[0, 0].plot([0, 1], [0, 1], "k--", lw=1)
axes[0, 0].set_title("ROC Curve", fontsize=14)
axes[0, 0].set_xlabel("False Positive Rate")
axes[0, 0].set_ylabel("True Positive Rate")
axes[0, 0].legend()
axes[0, 0].grid(True)

# PR 曲线
axes[0, 1].plot(recall_lr, precision_lr, label="Logistic Regression", color="dodgerblue", linewidth=2)
axes[0, 1].plot(recall_xgb, precision_xgb, label="XGBoost", color="orange", linewidth=2)
axes[0, 1].set_title("Precision-Recall Curve", fontsize=14)
axes[0, 1].set_xlabel("Recall")
axes[0, 1].set_ylabel("Precision")
axes[0, 1].legend()
axes[0, 1].grid(True)

# 混淆矩阵 - 逻辑回归
sns.heatmap(cm_lr, annot=True, fmt="d", cmap="Blues", ax=axes[1, 0])
axes[1, 0].set_title("Confusion Matrix - Logistic Regression", fontsize=14)
axes[1, 0].set_xlabel("Predicted Label")
axes[1, 0].set_ylabel("True Label")

# 混淆矩阵 - XGBoost
sns.heatmap(cm_xgb, annot=True, fmt="d", cmap="Oranges", ax=axes[1, 1])
axes[1, 1].set_title("Confusion Matrix - XGBoost", fontsize=14)
axes[1, 1].set_xlabel("Predicted Label")
axes[1, 1].set_ylabel("True Label")

plt.tight_layout()
plt.suptitle("模型性能对比图（Logistic Regression vs XGBoost）", fontsize=18, y=1.02)
plt.subplots_adjust(top=0.92)
